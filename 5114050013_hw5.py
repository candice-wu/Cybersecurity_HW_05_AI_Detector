import streamlit as st
import os
import pandas as pd
import time
import sys

# å°å…¥å‡½å¼åº«ä»¥ç²å–ç‰ˆæœ¬è™Ÿ
import sklearn
import plotly
import altair as alt

# å¾ src å°å…¥æ¨¡çµ„
from src.model import train_model, load_model, predict_text, FEATURE_COLUMNS
from src.visualization import plot_gauge_chart, plot_confusion_matrix, display_metrics

# --- æ‡‰ç”¨ç¨‹å¼è¨­å®š ---
st.set_page_config(
    page_title="AI æ–‡æœ¬åµæ¸¬å™¨",
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- æœƒè©±ç‹€æ…‹åˆå§‹åŒ– ---
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'model_info' not in st.session_state:
    # åœ¨å•Ÿå‹•æ™‚å°±è¼‰å…¥ä¸€æ¬¡æ¨¡å‹è³‡è¨Š
    st.session_state.model_info = load_model()


# --- å…¨å±€æ¨¡å‹è¼‰å…¥ ---
@st.cache_resource
def get_model_from_info(model_info):
    """å¾å·²è¼‰å…¥çš„ model_info ä¸­æå–æ¨¡å‹å’Œæ¨™ç±¤ç·¨ç¢¼å™¨ã€‚"""
    if model_info:
        return model_info.get("model"), model_info.get("label_encoder")
    return None, None

model, le = get_model_from_info(st.session_state.model_info)

# --- å´é‚Šæ¬„ ---
st.sidebar.title("âš™ï¸ ç³»çµ±è³‡è¨Š")

with st.sidebar.expander("ğŸ¤– æ¨¡å‹è³‡è¨Š", expanded=True):
    if model:
        st.success("æ¨¡å‹å·²æˆåŠŸè¼‰å…¥ã€‚")
    else:
        st.error("æ¨¡å‹æª”æ¡ˆ `model.joblib` éºå¤±ï¼è«‹å…ˆåœ¨æœ¬æ©Ÿç«¯åŸ·è¡Œ `python -m src.model` ä¾†ç”¢ç”Ÿæ¨¡å‹æª”æ¡ˆã€‚")

with st.sidebar.expander("â„¹ï¸ é–‹ç™¼èˆ‡ç’°å¢ƒ"):
    st.write("**é–‹ç™¼è€…:** Candice Wu")
    st.write(f"**Python ç‰ˆæœ¬:** {sys.version.split(' ')[0]}")
    st.write(f"**Streamlit ç‰ˆæœ¬:** {st.__version__}")
    st.write(f"**Scikit-learn ç‰ˆæœ¬:** {sklearn.__version__}")
    st.write(f"**Pandas ç‰ˆæœ¬:** {pd.__version__}")
    st.write(f"**Plotly ç‰ˆæœ¬:** {plotly.__version__}")
    st.write(f"**Altair ç‰ˆæœ¬:** {alt.__version__}")

st.sidebar.markdown("---")
st.sidebar.write("Â© 2025 Candice Wu. All Rights Reserved.")
st.sidebar.write("æœ€å¾Œæ›´æ–°: 2025-12-25")


# --- ä¸»é é¢ ---
st.title("ğŸ¤– AI æ–‡æœ¬åµæ¸¬å™¨")
st.write("æª¢æ¸¬è¼¸å…¥çš„æ–‡å­—å…§å®¹æ˜¯ç”± AI ç”Ÿæˆé‚„æ˜¯äººé¡æ’°å¯«ã€‚")

# --- æ–‡æœ¬åˆ†æè¼¸å…¥å€ ---
st.header("ğŸ” è¼¸å…¥æ–‡æœ¬é€²è¡Œåˆ†æ")
user_input = st.text_area(
    "è«‹åœ¨æ­¤è™•è²¼ä¸Šæ‚¨è¦åˆ†æçš„æ–‡æœ¬ï¼š",
    height=200,
    placeholder="åœ¨æ­¤è¼¸å…¥æˆ–è²¼ä¸Šæ–‡æœ¬..."
)
uploaded_file = st.file_uploader("æˆ–ä¸Šå‚³ä¸€å€‹ .txt æ–‡ä»¶é€²è¡Œåˆ†æ", type="txt")

if st.button("é–‹å§‹åˆ†æ", type="primary"):
    text_to_analyze = ""
    if user_input:
        text_to_analyze = user_input
    elif uploaded_file is not None:
        text_to_analyze = uploaded_file.read().decode("utf-8")

    if not text_to_analyze.strip():
        st.warning("è«‹è¼¸å…¥æˆ–ä¸Šå‚³æœ‰æ•ˆçš„æ–‡æœ¬å…§å®¹ã€‚")
    elif model is None:
        st.error("æ¨¡å‹æª”æ¡ˆéºå¤±ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚")
    else:
        start_time = time.time()
        with st.spinner("æ­£åœ¨åˆ†ææ–‡æœ¬..."):
            prediction, confidence = predict_text(text_to_analyze, model, le)
            ai_prob = confidence if prediction.lower() == 'ai' else 1 - confidence
        
        end_time = time.time()
        processing_time = end_time - start_time
        word_count = len(text_to_analyze.split())
        words_per_sec = word_count / processing_time if processing_time > 0 else 0

        st.session_state.analysis_results = {
            "text": text_to_analyze,
            "prediction": prediction,
            "confidence": confidence,
            "ai_prob": ai_prob,
            "processing_time": processing_time,
            "word_count": word_count,
            "words_per_sec": words_per_sec
        }

# --- çµæœé¡¯ç¤ºå€ ---
if st.session_state.analysis_results:
    st.markdown("---")
    st.header("ğŸ“Š åˆ†æçµæœ")
    
    results = st.session_state.analysis_results
    ai_prob = results["ai_prob"]
    
    col1, col2 = st.columns([0.6, 0.4])
    
    with col1:
        st.plotly_chart(plot_gauge_chart(ai_prob), use_container_width=True)

    with col2:
        st.subheader("åˆ¤å®šçµæœ")
        if results["prediction"].lower() == "ai":
            st.error(f"AI ç”Ÿæˆ ({results['confidence']*100:.2f}%)")
        else:
            st.success(f"äººé¡æ’°å¯« ({results['confidence']*100:.2f}%)")
        st.write("æ­¤çµæœåŸºæ–¼æ¨¡å‹çš„æ©Ÿç‡åˆ†ä½ˆã€‚")

    with st.expander("ğŸ” åˆ¤å®šåŸå› èˆ‡è©•æ¯”æŒ‡æ¨™"):
        st.write("""
            æˆ‘å€‘çš„æ¨¡å‹é€éåˆ†ææ–‡æœ¬çš„å¤šé …çµ±è¨ˆèˆ‡é¢¨æ ¼ç‰¹å¾µä¾†åšå‡ºåˆ¤æ–·ã€‚å®ƒä¸¦éç†è§£æ–‡æœ¬çš„èªæ„ï¼Œè€Œæ˜¯è­˜åˆ¥ AI ç”Ÿæˆå…§å®¹èˆ‡äººé¡å¯«ä½œåœ¨æ¨¡å¼ä¸Šçš„å·®ç•°ã€‚
            ä¸»è¦è©•æ¯”çš„ç‰¹å¾µç¶­åº¦åŒ…æ‹¬ï¼š
        """)
        st.json(FEATURE_COLUMNS)
        st.write("æ¨¡å‹æœƒç¶œåˆé€™äº›ç‰¹å¾µçš„æ•¸å€¼ï¼Œèˆ‡è¨“ç·´è³‡æ–™ä¸­å­¸ç¿’åˆ°çš„æ¨¡å¼é€²è¡Œæ¯”å°ï¼Œæœ€çµ‚çµ¦å‡ºä¸€å€‹å¯èƒ½æ€§åˆ¤æ–·ã€‚")

    with st.expander("â±ï¸ ç³»çµ±æ€§èƒ½æŒ‡æ¨™"):
        perf_col1, perf_col2, perf_col3 = st.columns(3)
        perf_col1.metric("è™•ç†æ™‚é–“", f"{results['processing_time']:.2f} ç§’")
        perf_col2.metric("åˆ†æå­—æ•¸", f"{results['word_count']} å­—")
        perf_col3.metric("è™•ç†é€Ÿåº¦", f"{results['words_per_sec']:.0f} å­—/ç§’")

# --- æ¨¡å‹æ•ˆèƒ½é¡¯ç¤ºå€ ---
if st.session_state.model_info:
    st.markdown("---")
    st.header("ğŸ“ˆ ç•¶å‰æ¨¡å‹æ•ˆèƒ½")
    
    model_results = st.session_state.model_info
    y_test_labels_upper = [label.capitalize() for label in model_results["y_test"]]
    y_pred_labels_upper = [label.capitalize() for label in model_results["y_pred"]]
    class_labels = sorted(list(set(y_test_labels_upper)))

    display_metrics(y_test_labels_upper, y_pred_labels_upper, labels=class_labels)
    
    m_col1, m_col2 = st.columns(2)
    with m_col1:
        st.write("#### ç‰¹å¾µé‡è¦æ€§")
        st.dataframe(pd.Series(model_results["model"].feature_importances_, index=model_results["feature_columns"]).sort_values(ascending=False).round(4))
    with m_col2:
        st.write("#### æ··æ·†çŸ©é™£")
        st.plotly_chart(plot_confusion_matrix(y_test_labels_upper, y_pred_labels_upper, labels=class_labels), use_container_width=True)
else:
    st.markdown("---")
    st.warning("æ‰¾ä¸åˆ°æ¨¡å‹æ•ˆèƒ½è³‡è¨Šã€‚è«‹ç¢ºä¿ `model.joblib` åŒ…å«è©•ä¼°æ•¸æ“šã€‚")
