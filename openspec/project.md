# 專案背景

## 專案目標
本專案旨在建立一個「AI 文本偵測器」，用於區分由人工智慧生成及人類撰寫的文本。此工具將透過 Streamlit 網頁介面呈現，並提供豐富的視覺化分析結果及模型效能指標。

## 技術棧
- **程式語言:** Python
- **網頁框架:** Streamlit
- **機器學習:** scikit-learn
- **資料處理:** Pandas, NumPy
- **自然語言處理與特徵工程:** NLTK, spaCy
- **資料視覺化:** Plotly, Matplotlib, Seaborn

## 專案慣例

### 程式碼風格
- 遵循 PEP 8 程式碼風格指南。
- 使用 `black` 進行統一的程式碼格式化。
- 使用 `isort` 整理 import 語句。
- 所有函數簽名均需添加型別提示。

### 架構模式
- **模組化設計:** 應用程式將分為不同模組，例如：
  - `src/data_loader.py`: 負責資料集載入。
  - `src/feature_engineering.py`: 負責文本特徵提取。
  - `src/model.py`: 負責模型訓練與評估。
  - `src/visualization.py`: 負責生成圖表。
- **主應用程式:** `5114050013_hw5.py` 將作為 Streamlit 應用程式的主要入口點。

### 測試策略
- 使用 `pytest` 編寫單元測試。
- 測試重點區域包括：
  - 特徵提取邏輯。
  - 模型預測準確性。
  - 資料載入與預處理。
- 測試檔案將存放於 `tests/` 目錄中。

### Git 工作流程
- **主分支:** `main`
- **功能分支:** `feature/<功能名稱>` (例如：`feature/add-svm-model`)
- 所有新功能開發皆需在功能分支上進行，完成後透過 Pull Request 合併至 `main` 分支。
- Pull Request 必須通過所有自動化檢查 (例如：linting, testing) 才能合併。

## 領域知識
- **困惑度 (Perplexity):** 衡量機率分佈或機率模型預測樣本的優劣程度。在自然語言處理中，較低的困惑度表示模型對其生成的文本更具信心。我們將以此作為區分 AI 文本與人類文本的特徵之一。
- **自訂特徵:** 我們將設計並提取諸如句子長度、標點符號頻率、特定停用詞使用情況以及文本複雜度評分等特徵，用於訓練模型。

## 重要限制
- 初始訓練及評估資料集需要自行收集與預處理。我們應尋找可靠的 AI 生成文本和人類撰寫文本來源。
- 模型應足夠高效，以便在 Streamlit 應用程式中提供接近即時的預測。

## 外部依賴
- 我們將依賴預訓練的語言模型或函式庫 (例如 NLTK, spaCy) 進行部分自然語言處理任務。
- 應用程式將部署於 Streamlit Cloud 或類似服務上。
